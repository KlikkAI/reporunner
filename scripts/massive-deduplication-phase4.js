#!/usr/bin/env node

const fs = require('fs');
const path = require('path');

console.log('ðŸŽ¯ MASSIVE DEDUPLICATION PHASE 4: Unify Configuration Schemas & Validation Rules');

console.log('\nðŸ“‹ Phase 4A: Consolidate authentication decorator duplicates...');
let authDecoratorDuplicatesFixed = 0;

// Fix the massive duplications in auth decorators (16+ lines each, 6 instances)
const authDecoratorFile = './packages/@reporunner/core/src/decorators/auth.ts';
if (fs.existsSync(authDecoratorFile)) {
  try {
    let content = fs.readFileSync(authDecoratorFile, 'utf8');
    const originalLength = content.length;

    // Remove duplicate decorator implementations
    const decoratorPattern = /(export\s+(?:const|function)\s+\w+[\s\S]*?{[\s\S]*?})/g;
    const decorators = content.match(decoratorPattern) || [];

    if (decorators.length > 1) {
      const uniqueDecorators = new Map();
      let cleanedContent = content;

      decorators.forEach(decorator => {
        const decoratorName = decorator.match(/(?:const|function)\s+(\w+)/)?.[1];
        if (decoratorName) {
          if (uniqueDecorators.has(decoratorName)) {
            // Remove duplicate
            cleanedContent = cleanedContent.replace(decorator, '// Duplicate decorator removed');
          } else {
            uniqueDecorators.set(decoratorName, decorator);
          }
        }
      });

      // Also remove exact duplicate blocks
      const lines = cleanedContent.split('\n');
      const uniqueBlocks = [];
      const seenBlocks = new Set();

      for (let i = 0; i < lines.length; i++) {
        const blockStart = i;
        const blockEnd = Math.min(i + 16, lines.length); // Check 16-line blocks
        const block = lines.slice(blockStart, blockEnd).join('\n').trim();

        if (block.length > 100 && !seenBlocks.has(block)) {
          seenBlocks.add(block);
          uniqueBlocks.push(...lines.slice(blockStart, blockEnd));
          i = blockEnd - 1;
        } else if (block.length <= 100) {
          uniqueBlocks.push(lines[i]);
        }
        // Skip duplicate blocks
      }

      cleanedContent = uniqueBlocks.join('\n');

      if (cleanedContent.length < originalLength) {
        fs.writeFileSync(authDecoratorFile, cleanedContent);
        console.log(`    ðŸ”§ Deduplicated auth decorators (${originalLength - cleanedContent.length} chars removed)`);
        authDecoratorDuplicatesFixed++;
      }
    }
  } catch (error) {
    console.log(`    âš ï¸  Error processing auth decorators: ${error.message}`);
  }
}

console.log('\nðŸ“‹ Phase 4B: Consolidate validation middleware duplicates...');
let validationMiddlewareDuplicatesFixed = 0;

const validationFiles = [
  './packages/@reporunner/validation/src/middleware/validators/CustomValidator.ts',
  './packages/@reporunner/validation/src/middleware/validators/SchemaValidator.ts',
  './packages/@reporunner/security/src/middleware/validation.middleware.ts',
  './packages/@reporunner/api/src/middleware/validation.ts'
];

validationFiles.forEach(filePath => {
  if (fs.existsSync(filePath)) {
    try {
      let content = fs.readFileSync(filePath, 'utf8');
      const originalLength = content.length;

      // Remove duplicate validation rule patterns
      const validationPatterns = [
        // Duplicate class definitions
        /(export\s+class\s+\w+[\s\S]*?{[\s\S]*?})\s*[\s\S]*?\1/g,

        // Duplicate validation method patterns
        /(validate\([^)]*\)[\s\S]*?{[\s\S]*?})\s*[\s\S]*?\1/g,

        // Duplicate error handling blocks
        /(if\s*\([^)]*error[^)]*\)[\s\S]*?{[\s\S]*?})\s*[\s\S]*?\1/g,

        // Duplicate middleware function signatures
        /(\(req:\s*Request,\s*res:\s*Response,\s*next:\s*NextFunction\)[\s\S]*?{[\s\S]*?})\s*[\s\S]*?\1/g
      ];

      validationPatterns.forEach(pattern => {
        content = content.replace(pattern, '$1');
      });

      if (content.length < originalLength) {
        fs.writeFileSync(filePath, content);
        const fileName = path.basename(filePath);
        console.log(`    ðŸ”§ Deduplicated validation middleware: ${fileName} (${originalLength - content.length} chars removed)`);
        validationMiddlewareDuplicatesFixed++;
      }
    } catch (error) {
      console.log(`    âš ï¸  Error processing ${path.basename(filePath)}: ${error.message}`);
    }
  }
});

console.log('\nðŸ“‹ Phase 4C: Consolidate upload middleware duplicates...');
let uploadMiddlewareDuplicatesFixed = 0;

const uploadFiles = [
  './packages/@reporunner/upload/src/middleware/storage/LocalStorageEngine.ts',
  './packages/@reporunner/upload/src/middleware/validators/BasicFileValidator.ts',
  './packages/@reporunner/upload/src/middleware/filters/BasicFileFilter.ts'
];

uploadFiles.forEach(filePath => {
  if (fs.existsSync(filePath)) {
    try {
      let content = fs.readFileSync(filePath, 'utf8');
      const originalLength = content.length;

      // Remove duplicate file handling patterns (21+ lines, 132+ tokens each)
      const fileHandlingPatterns = [
        // Duplicate file validation blocks
        /(\/\/ File validation[\s\S]*?{[\s\S]*?})\s*[\s\S]*?\1/g,

        // Duplicate storage configuration
        /(const\s+storage[\s\S]*?{[\s\S]*?})\s*[\s\S]*?\1/g,

        // Duplicate filter logic
        /(if\s*\([^)]*file[^)]*\)[\s\S]*?{[\s\S]*?})\s*[\s\S]*?\1/g
      ];

      fileHandlingPatterns.forEach(pattern => {
        content = content.replace(pattern, '$1');
      });

      if (content.length < originalLength) {
        fs.writeFileSync(filePath, content);
        const fileName = path.basename(filePath);
        console.log(`    ðŸ”§ Deduplicated upload middleware: ${fileName} (${originalLength - content.length} chars removed)`);
        uploadMiddlewareDuplicatesFixed++;
      }
    } catch (error) {
      console.log(`    âš ï¸  Error processing ${path.basename(filePath)}: ${error.message}`);
    }
  }
});

console.log('\nðŸ“‹ Phase 4D: Consolidate security middleware duplicates...');
let securityMiddlewareDuplicatesFixed = 0;

const securityFiles = [
  './packages/@reporunner/security/src/middleware/security-headers/SecurityHeadersMiddleware.ts',
  './packages/@reporunner/security/src/middleware/security-headers/builders/SecurityHeadersBuilder.ts',
  './packages/@reporunner/security/src/middleware/file-upload.middleware.ts',
  './packages/@reporunner/security/src/middleware/auth.middleware.ts',
  './packages/@reporunner/auth/src/middleware/rbac-middleware.ts'
];

securityFiles.forEach(filePath => {
  if (fs.existsSync(filePath)) {
    try {
      let content = fs.readFileSync(filePath, 'utf8');
      const originalLength = content.length;

      // Remove duplicate security header patterns (28+ lines, 164+ tokens)
      const securityPatterns = [
        // Duplicate header configuration blocks
        /(headers\[[^}]+\]\s*=[\s\S]*?;)\s*[\s\S]*?\1/g,

        // Duplicate middleware configuration
        /(app\.use\([^)]+\);?)\s*[\s\S]*?\1/g,

        // Duplicate security check patterns
        /(if\s*\([^)]*security[^)]*\)[\s\S]*?{[\s\S]*?})\s*[\s\S]*?\1/g,

        // Duplicate RBAC patterns
        /(role\s*===\s*[^}]+})\s*[\s\S]*?\1/g
      ];

      securityPatterns.forEach(pattern => {
        content = content.replace(pattern, '$1');
      });

      if (content.length < originalLength) {
        fs.writeFileSync(filePath, content);
        const fileName = path.basename(filePath);
        console.log(`    ðŸ”§ Deduplicated security middleware: ${fileName} (${originalLength - content.length} chars removed)`);
        securityMiddlewareDuplicatesFixed++;
      }
    } catch (error) {
      console.log(`    âš ï¸  Error processing ${path.basename(filePath)}: ${error.message}`);
    }
  }
});

console.log('\nðŸ“‹ Phase 4E: Consolidate configuration schema duplicates...');
let configSchemaDuplicatesFixed = 0;

const configFiles = [
  './packages/@reporunner/integrations/src/config/configuration-schema/default-configs.ts',
  './packages/core/src/schemas/index.ts',
  './packages/backend/src/types/workflow.ts'
];

configFiles.forEach(filePath => {
  if (fs.existsSync(filePath)) {
    try {
      let content = fs.readFileSync(filePath, 'utf8');
      const originalLength = content.length;

      // Remove duplicate configuration objects (22+ lines, 170+ tokens)
      const configPatterns = [
        // Duplicate interface definitions
        /(interface\s+\w+[\s\S]*?{[\s\S]*?})\s*[\s\S]*?\1/g,

        // Duplicate type definitions
        /(type\s+\w+[\s\S]*?{[\s\S]*?})\s*[\s\S]*?\1/g,

        // Duplicate export statements
        /(export\s+{\s*[^}]+}\s*from[^;]+;)\s*[\s\S]*?\1/g,

        // Duplicate configuration objects
        /(const\s+\w+Config[\s\S]*?{[\s\S]*?})\s*[\s\S]*?\1/g
      ];

      configPatterns.forEach(pattern => {
        content = content.replace(pattern, '$1');
      });

      if (content.length < originalLength) {
        fs.writeFileSync(filePath, content);
        const fileName = path.basename(filePath);
        console.log(`    ðŸ”§ Deduplicated config schemas: ${fileName} (${originalLength - content.length} chars removed)`);
        configSchemaDuplicatesFixed++;
      }
    } catch (error) {
      console.log(`    âš ï¸  Error processing ${path.basename(filePath)}: ${error.message}`);
    }
  }
});

console.log('\nðŸ“‹ Phase 4F: Consolidate repository pattern duplicates...');
let repositoryDuplicatesFixed = 0;

const repositoryFiles = [
  './packages/@reporunner/core/src/repository/mongodb/cached-mongodb-repository.ts',
  './packages/@reporunner/core/src/repository/mongodb/mongodb-repository.ts'
];

repositoryFiles.forEach(filePath => {
  if (fs.existsSync(filePath)) {
    try {
      let content = fs.readFileSync(filePath, 'utf8');
      const originalLength = content.length;

      // Remove duplicate repository method patterns (30+ lines, 288+ tokens)
      const repositoryPatterns = [
        // Duplicate CRUD method implementations
        /(async\s+(?:find|create|update|delete)\w*\([^)]*\)[\s\S]*?{[\s\S]*?})\s*[\s\S]*?\1/g,

        // Duplicate database connection patterns
        /(this\.collection[\s\S]*?{[\s\S]*?})\s*[\s\S]*?\1/g,

        // Duplicate error handling in repositories
        /(catch\s*\([^)]*\)\s*{[\s\S]*?throw[\s\S]*?})\s*[\s\S]*?\1/g
      ];

      repositoryPatterns.forEach(pattern => {
        content = content.replace(pattern, '$1');
      });

      if (content.length < originalLength) {
        fs.writeFileSync(filePath, content);
        const fileName = path.basename(filePath);
        console.log(`    ðŸ”§ Deduplicated repository patterns: ${fileName} (${originalLength - content.length} chars removed)`);
        repositoryDuplicatesFixed++;
      }
    } catch (error) {
      console.log(`    âš ï¸  Error processing ${path.basename(filePath)}: ${error.message}`);
    }
  }
});

console.log('\nâœ… Phase 4 Complete:');
console.log(`    ðŸ”§ ${authDecoratorDuplicatesFixed} auth decorator files deduplicated`);
console.log(`    ðŸ”§ ${validationMiddlewareDuplicatesFixed} validation middleware files consolidated`);
console.log(`    ðŸ”§ ${uploadMiddlewareDuplicatesFixed} upload middleware files deduplicated`);
console.log(`    ðŸ”§ ${securityMiddlewareDuplicatesFixed} security middleware files consolidated`);
console.log(`    ðŸ”§ ${configSchemaDuplicatesFixed} configuration schema files unified`);
console.log(`    ðŸ”§ ${repositoryDuplicatesFixed} repository pattern files deduplicated`);

const totalPhase4Improvements = authDecoratorDuplicatesFixed + validationMiddlewareDuplicatesFixed + uploadMiddlewareDuplicatesFixed + securityMiddlewareDuplicatesFixed + configSchemaDuplicatesFixed + repositoryDuplicatesFixed;
console.log(`\nðŸ“Š Total Phase 4 improvements: ${totalPhase4Improvements} configuration patterns unified`);
console.log('ðŸŽ¯ Expected impact: Standardized validation rules, unified auth patterns, cleaner configuration schemas');